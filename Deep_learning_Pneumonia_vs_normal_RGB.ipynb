{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_learning_Pneumonia_vs_normal_RGB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1mYSw+52UO2qUF06pKGJE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Rezaei/Deep_Learning_Pneumonia_vs_Normal/blob/main/Deep_learning_Pneumonia_vs_normal_RGB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erW1pQ3hDosL"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onaHcbmcBSna",
        "outputId": "f5f38cfe-17d9-47ac-d8de-ddce494b7930"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzRr8dn7D0ls",
        "outputId": "b8feb42b-5e65-4ac2-b7df-ee6119ca101b"
      },
      "source": [
        "main_directory = \"/content/gdrive/MyDrive/Deep_Learning_projects/Pneumonia_vs_normal/data/\"\n",
        "train_data_dir = main_directory + \"train/\"\n",
        "validation_data_dir = main_directory + \"val/\"\n",
        "\n",
        "epochs =20\n",
        "batch_size = 16\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "train_normal = train_data_dir + \"NORMAL/\"\n",
        "train_pneumonia = train_data_dir + \"PNEUMONIA/\"\n",
        "img_height, img_width = 256, 256\n",
        "\n",
        "print(\"\\nLoading training data...\")\n",
        "\n",
        "training_data_generator = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05)\n",
        "\n",
        "training_iterator = training_data_generator.flow_from_directory(train_data_dir, \n",
        "                                                                class_mode='categorical', \n",
        "                                                                target_size=(img_width, img_height), \n",
        "                                                                color_mode='rgb',\n",
        "                                                                batch_size=batch_size)\n",
        "\n",
        "\n",
        "print(\"\\nLoading validation data...\")\n",
        "\n",
        "validation_data_generator = ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "validation_iterator = validation_data_generator.flow_from_directory(validation_data_dir, class_mode='categorical', target_size=(img_width, img_height), color_mode='rgb',batch_size=batch_size)\n",
        "\n",
        "print(\"\\nBuilding model...\")\n",
        "###  model\n",
        "model = Sequential()\n",
        "model.add(tf.keras.Input(shape=(256, 256, 3)))\n",
        "model.add(Conv2D(32, 5, strides=3, padding=\"same\")) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(5, 5), strides=(5,5)))\n",
        "model.add(Conv2D(1, 3, strides=1, padding=\"same\")) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(Dense(2,activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print(\"\\nCompiling model...\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.AUC()])\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nTraining model...\")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "       training_iterator,\n",
        "       steps_per_epoch=int(training_iterator.samples/batch_size),\n",
        "       epochs=epochs,\n",
        "       validation_data=validation_iterator,\n",
        "       validation_steps=int(validation_iterator.samples/batch_size), verbose=1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading training data...\n",
            "Found 5216 images belonging to 2 classes.\n",
            "\n",
            "Loading validation data...\n",
            "Found 16 images belonging to 2 classes.\n",
            "\n",
            "Building model...\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 86, 86, 32)        2432      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 86, 86, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 86, 86, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 17, 17, 1)         289       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 17, 17, 1)         4         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 17, 17, 1)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 1)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,983\n",
            "Trainable params: 2,917\n",
            "Non-trainable params: 66\n",
            "_________________________________________________________________\n",
            "\n",
            "Compiling model...\n",
            "\n",
            "Training model...\n",
            "Epoch 1/20\n",
            "326/326 [==============================] - 1570s 5s/step - loss: 0.3200 - categorical_accuracy: 0.8639 - auc: 0.9372 - val_loss: 0.9744 - val_categorical_accuracy: 0.5000 - val_auc: 0.4609\n",
            "Epoch 2/20\n",
            "326/326 [==============================] - 196s 600ms/step - loss: 0.2376 - categorical_accuracy: 0.9036 - auc: 0.9655 - val_loss: 0.3855 - val_categorical_accuracy: 0.7500 - val_auc: 0.9102\n",
            "Epoch 3/20\n",
            "326/326 [==============================] - 192s 587ms/step - loss: 0.2173 - categorical_accuracy: 0.9089 - auc: 0.9710 - val_loss: 0.7349 - val_categorical_accuracy: 0.5000 - val_auc: 0.6055\n",
            "Epoch 4/20\n",
            "326/326 [==============================] - 190s 584ms/step - loss: 0.2122 - categorical_accuracy: 0.9089 - auc: 0.9725 - val_loss: 1.1292 - val_categorical_accuracy: 0.6875 - val_auc: 0.7461\n",
            "Epoch 5/20\n",
            "326/326 [==============================] - 189s 579ms/step - loss: 0.2008 - categorical_accuracy: 0.9149 - auc: 0.9754 - val_loss: 1.9672 - val_categorical_accuracy: 0.6250 - val_auc: 0.6523\n",
            "Epoch 6/20\n",
            "326/326 [==============================] - 190s 584ms/step - loss: 0.1939 - categorical_accuracy: 0.9206 - auc: 0.9769 - val_loss: 0.8920 - val_categorical_accuracy: 0.5000 - val_auc: 0.5781\n",
            "Epoch 7/20\n",
            "326/326 [==============================] - 194s 593ms/step - loss: 0.2062 - categorical_accuracy: 0.9135 - auc: 0.9740 - val_loss: 0.9006 - val_categorical_accuracy: 0.5000 - val_auc: 0.5625\n",
            "Epoch 8/20\n",
            "326/326 [==============================] - 188s 577ms/step - loss: 0.1897 - categorical_accuracy: 0.9233 - auc: 0.9779 - val_loss: 0.5134 - val_categorical_accuracy: 0.7500 - val_auc: 0.8359\n",
            "Epoch 9/20\n",
            "326/326 [==============================] - 182s 557ms/step - loss: 0.1845 - categorical_accuracy: 0.9250 - auc: 0.9792 - val_loss: 0.5726 - val_categorical_accuracy: 0.7500 - val_auc: 0.8086\n",
            "Epoch 10/20\n",
            "326/326 [==============================] - 180s 553ms/step - loss: 0.1986 - categorical_accuracy: 0.9149 - auc: 0.9760 - val_loss: 0.4449 - val_categorical_accuracy: 0.8750 - val_auc: 0.8867\n",
            "Epoch 11/20\n",
            "326/326 [==============================] - 183s 562ms/step - loss: 0.2011 - categorical_accuracy: 0.9178 - auc: 0.9752 - val_loss: 0.7209 - val_categorical_accuracy: 0.7500 - val_auc: 0.7812\n",
            "Epoch 12/20\n",
            "326/326 [==============================] - 183s 562ms/step - loss: 0.1860 - categorical_accuracy: 0.9287 - auc: 0.9786 - val_loss: 0.5642 - val_categorical_accuracy: 0.7500 - val_auc: 0.8438\n",
            "Epoch 13/20\n",
            "326/326 [==============================] - 183s 560ms/step - loss: 0.1885 - categorical_accuracy: 0.9195 - auc: 0.9784 - val_loss: 0.4371 - val_categorical_accuracy: 0.7500 - val_auc: 0.8906\n",
            "Epoch 14/20\n",
            "326/326 [==============================] - 187s 572ms/step - loss: 0.1934 - categorical_accuracy: 0.9222 - auc: 0.9771 - val_loss: 0.6989 - val_categorical_accuracy: 0.7500 - val_auc: 0.7930\n",
            "Epoch 15/20\n",
            "326/326 [==============================] - 184s 565ms/step - loss: 0.1891 - categorical_accuracy: 0.9266 - auc: 0.9779 - val_loss: 1.5812 - val_categorical_accuracy: 0.6250 - val_auc: 0.6953\n",
            "Epoch 16/20\n",
            "326/326 [==============================] - 183s 561ms/step - loss: 0.1782 - categorical_accuracy: 0.9291 - auc: 0.9805 - val_loss: 0.4988 - val_categorical_accuracy: 0.7500 - val_auc: 0.8477\n",
            "Epoch 17/20\n",
            "326/326 [==============================] - 183s 562ms/step - loss: 0.1881 - categorical_accuracy: 0.9212 - auc: 0.9782 - val_loss: 0.5917 - val_categorical_accuracy: 0.6875 - val_auc: 0.7773\n",
            "Epoch 18/20\n",
            "326/326 [==============================] - 183s 560ms/step - loss: 0.1843 - categorical_accuracy: 0.9254 - auc: 0.9790 - val_loss: 1.0015 - val_categorical_accuracy: 0.6250 - val_auc: 0.7344\n",
            "Epoch 19/20\n",
            "326/326 [==============================] - 182s 557ms/step - loss: 0.1811 - categorical_accuracy: 0.9273 - auc: 0.9798 - val_loss: 0.5453 - val_categorical_accuracy: 0.7500 - val_auc: 0.7891\n",
            "Epoch 20/20\n",
            "326/326 [==============================] - 182s 557ms/step - loss: 0.1799 - categorical_accuracy: 0.9247 - auc: 0.9801 - val_loss: 1.7894 - val_categorical_accuracy: 0.6250 - val_auc: 0.6914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c12a7ba50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCZPCn_k291W"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGj_HjWR4e1q"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('chestxray_cnn_model_RGB_4.h5')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf11PXSD4xVM",
        "outputId": "cd9f1b8c-b4a7-4f61-842d-63eaf2796924"
      },
      "source": [
        "test_data_dir = main_directory + \"test/\"\n",
        "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_iterator = test_data_generator.flow_from_directory(test_data_dir, \n",
        "                                                        class_mode='categorical', \n",
        "                                                        target_size=(img_width, img_height), \n",
        "                                                        color_mode='rgb',\n",
        "                                                        batch_size=batch_size)\n",
        "\n",
        "scores = model.evaluate(test_iterator)\n",
        "\n",
        "print(\"Loss of the model: %.2f\"%(scores[0]))\n",
        "print(\"Test Accuracy: %.2f%%\"%(scores[1] * 100))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "39/39 [==============================] - 147s 4s/step - loss: 0.6993 - categorical_accuracy: 0.7917 - auc: 0.8815\n",
            "Loss of the model: 0.70\n",
            "Test Accuracy: 79.17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0nybOQAggFG",
        "outputId": "839ea698-1c31-4838-df08-ea03c91a4c87"
      },
      "source": [
        "def predict_image(filename):\n",
        "    img = load_img(filename, target_size=(img_height, img_width))\n",
        "    image = keras.preprocessing.image.img_to_array(img)\n",
        "    image = image / 255.0\n",
        "    print(image.shape)\n",
        "    #print(image.format)\n",
        "    image = image.reshape( 1, 256, 256, 3)\n",
        "    model = load_model('chestxray_cnn_model_RGB_4.h5')\n",
        "    prediction = model.predict(image)\n",
        "    #print(prediction)\n",
        "    print(prediction[0][1])\n",
        "    #print(prediction.shape)\n",
        "    #plt.imshow(img)\n",
        "    if(prediction[0][1] > 0.5):\n",
        "        print(\"predicted: PNEUMONIA\")\n",
        "    else:\n",
        "        print(\"predicted: NORMAL\")\n",
        "   \n",
        "predict_image(test_data_dir + \"PNEUMONIA/person1_virus_6.jpeg\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 3)\n",
            "0.9999999\n",
            "predicted: PNEUMONIA\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}